from transformers import AutoTokenizer, AutoModelForCausalLM

# âœ… Model Name (Ensure you have access)
MODEL_NAME = "meta-llama/Llama-3.1-8B-Instruct"

# âœ… Download the tokenizer
print("ðŸš€ Downloading tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

# âœ… Download the model (this may take time)
print("ðŸš€ Downloading model weights...")
model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)

print("âœ… Model download complete!")
